# ЁЯПе Diagnostics Module - р╕Др╕╣р╣Ир╕бр╕╖р╕нр╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щ

р╣Ар╕лр╕бр╕▓р╕░р╕кр╕│р╕лр╕гр╕▒р╕Ър╕бр╕╖р╕нр╣Гр╕лр╕бр╣И ML р╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕╕р╕Ур╕ар╕▓р╕Юр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕ер╕░р╕зр╕┤р╕Щр╕┤р╕Ир╕Йр╕▒р╕вр╕Ыр╕▒р╕Нр╕лр╕▓

---

## ЁЯУЪ р╕Яр╕▒р╕Зр╕Бр╣Мр╕Кр╕▒р╕Щр╕лр╕ер╕▒р╕Бр╕Чр╕╡р╣Ир╕бр╕╡

### 1. ЁЯФН **Data Quality Check**
```python
from kaggle_utils.diagnostics import check_data_quality

# р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕╕р╕Ур╕ар╕▓р╕Юр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Вр╕Фр╕вр╕гр╕зр╕б
report = check_data_quality(train_df, target_col='price', show_details=True)
```

**р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ:**
- тЬЕ Missing values (features р╕Чр╕╡р╣Ир╕бр╕╡ missing р╕бр╕▓р╕Бр╕Бр╕зр╣Ир╕▓ 50%)
- тЬЕ Constant features (р╣Др╕бр╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╣Бр╕Ыр╕гр╕Ыр╕гр╕зр╕Щ)
- тЬЕ Duplicate features (correlation > 0.95)
- тЬЕ High cardinality categorical features
- тЬЕ Target distribution р╣Бр╕ер╕░ class imbalance

**Output:**
```
ЁЯФН DATA QUALITY CHECK
=================================================================
тЪая╕П  3 features р╕бр╕╡ missing values > 50%
тЪая╕П  2 features р╕бр╕╡р╕Др╣Ир╕▓р╕Др╕Зр╕Чр╕╡р╣И (р╣Др╕бр╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╣Бр╕Ыр╕гр╕Ыр╕гр╕зр╕Щ)

ЁЯТб Suggestions:
   1. р╕Юр╕┤р╕Ир╕▓р╕гр╕Ур╕▓р╕ер╕Ъ features: ['col_A', 'col_B', 'col_C']
   2. р╕Др╕зр╕гр╕ер╕Ъ constant features: ['col_X', 'col_Y']
```

---

### 2. ЁЯЪи **Data Leakage Detection**
```python
from kaggle_utils.diagnostics import detect_leakage

# р╕Хр╕гр╕зр╕Ир╕Ир╕▒р╕Ъ data leakage
suspicious = detect_leakage(train_df, target_col='price', test_df=test_df, threshold=0.95)
```

**р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ:**
- тЬЕ Features р╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕▒р╕бр╕Юр╕▒р╕Щр╕Шр╣Мр╕кр╕╣р╕Зр╕Ьр╕┤р╕Фр╕Ыр╕Бр╕Хр╕┤р╕Бр╕▒р╕Ъ target (>0.95)
- тЬЕ Mutual Information р╕Чр╕╡р╣Ир╕кр╕╣р╕Зр╕Ьр╕┤р╕Фр╕Ыр╕Бр╕Хр╕┤
- тЬЕ Train-Test distribution differences
- тЬЕ Temporal leakage (р╕Ир╕▓р╕Б date columns)

**Output:**
```
тЪая╕П  р╕Юр╕Ъ 2 features р╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕▒р╕бр╕Юр╕▒р╕Щр╕Шр╣Мр╕кр╕╣р╕Зр╕Ьр╕┤р╕Фр╕Ыр╕Бр╕Хр╕┤р╕Бр╕▒р╕Ъ target (>0.95):
   - feature_A: 0.9823
   - feature_B: 0.9756

тЭМ р╕нр╕▓р╕Ир╣Ар╕Ыр╣Зр╕Щ Data Leakage! р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ features р╣Ар╕лр╕ер╣Ир╕▓р╕Щр╕╡р╣Й
```

---

### 3. ЁЯФЧ **Multicollinearity Check**
```python
from kaggle_utils.diagnostics import check_multicollinearity

# р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ features р╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕▒р╕бр╕Юр╕▒р╕Щр╕Шр╣Мр╕Бр╕▒р╕Щр╕кр╕╣р╕З
high_corr = check_multicollinearity(X_train, threshold=0.8)
```

**Output:**
```
тЪая╕П  р╕Юр╕Ъ 15 feature pairs р╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕▒р╕бр╕Юр╕▒р╕Щр╕Шр╣Мр╕кр╕╣р╕З (>0.8)

ЁЯТб р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│:
   1. р╕Юр╕┤р╕Ир╕▓р╕гр╕Ур╕▓р╕ер╕Ъ features р╕Чр╕╡р╣Ир╕Лр╣Йр╕│р╕Лр╣Йр╕нр╕Щ
   2. р╣Гр╕Кр╣Й PCA р╕лр╕гр╕╖р╕н feature selection
   3. р╣Гр╕Кр╣Й regularization (Ridge/Lasso)
```

---

### 4. ЁЯдЦ **Model Recommendation**
```python
from kaggle_utils.diagnostics import suggest_models

# р╣Бр╕Щр╕░р╕Щр╕│р╣Вр╕бр╣Ар╕Фр╕ер╕Чр╕╡р╣Ир╣Ар╕лр╕бр╕▓р╕░р╕кр╕б
recommendations = suggest_models(train_df, target_col='price', task='auto')
```

**р╣Бр╕Щр╕░р╕Щр╕│р╕Хр╕▓р╕б:**
- ЁЯУК Dataset size (small/medium/large)
- ЁЯУИ Sample/Feature ratio
- ЁЯУЭ Number of categorical features
- ЁЯОп Task type (regression/classification)

**Output:**
```
ЁЯУК Dataset Info:
   - Task: REGRESSION
   - Samples: 5,000
   - Features: 50
   - Sample/Feature Ratio: 100.0

ЁЯОп Recommended Models:
   1. ЁЯеЗ LightGBM / XGBoost
   2. ЁЯеИ Random Forest
   3. ЁЯеЙ CatBoost (р╕Цр╣Йр╕▓р╕бр╕╡ categorical features р╣Ар╕вр╕нр╕░)
```

---

### 5. ЁЯУЙ **Overfitting Detection**
```python
from kaggle_utils.diagnostics import detect_overfitting

# р╕Хр╕гр╕зр╕Ир╕Ир╕▒р╕Ъ overfitting/underfitting
result = detect_overfitting(
    model=rf_model, 
    X_train=X_train, y_train=y_train,
    X_val=X_val, y_val=y_val,
    task='regression'
)
```

**Output:**
```
ЁЯУК Performance Metrics:
   Train RMSE: 1234.56
   Val RMSE: 2345.67
   Gap: 1111.11 (90.0%)

тЭМ OVERFITTING detected!
ЁЯТб р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│:
   1. р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е training
   2. р╣Гр╕Кр╣Й regularization (Ridge, Lasso)
   3. р╕ер╕Ф model complexity (max_depth, n_estimators)
   4. р╣Гр╕Кр╣Й early stopping
```

---

### 6. ЁЯУИ **Learning Curve Analysis**
```python
from kaggle_utils.diagnostics import plot_learning_curve

# Plot learning curve
plot_learning_curve(model, X_train, y_train, cv=5)
```

**р╣Бр╕кр╕Фр╕З:**
- ЁЯУК Training score vs Validation score
- ЁЯУИ Score changes р╕Бр╕▒р╕Ър╕Вр╕Щр╕▓р╕Ф training set
- ЁЯФН р╕зр╕┤р╕Щр╕┤р╕Ир╕Йр╕▒р╕в overfitting/underfitting р╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤

---

### 7. ЁЯПе **Quick Diagnosis (All-in-One)**
```python
from kaggle_utils.diagnostics import quick_diagnosis

# р╕зр╕┤р╕Щр╕┤р╕Ир╕Йр╕▒р╕вр╕Фр╣Ир╕зр╕Щ - р╕гр╕зр╕бр╕Чр╕╕р╕Бр╕нр╕вр╣Ир╕▓р╕Зр╣Гр╕Щр╕Яр╕▒р╕Зр╕Бр╣Мр╕Кр╕▒р╕Щр╣Ар╕Фр╕╡р╕вр╕з!
report = quick_diagnosis(
    train_df=train_df,
    target_col='price',
    test_df=test_df,
    model=rf_model,  # optional
    X_val=X_val,     # optional
    y_val=y_val      # optional
)
```

**р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф:**
1. тЬЕ Data Quality
2. тЬЕ Data Leakage
3. тЬЕ Multicollinearity
4. тЬЕ Model Recommendation
5. тЬЕ Overfitting Check (р╕Цр╣Йр╕▓р╕бр╕╡ model)

**Output:**
```
ЁЯПе QUICK DIAGNOSIS - Comprehensive Data & Model Check
=================================================================

[... р╕гр╕▓р╕вр╕Зр╕▓р╕Щр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф ...]

ЁЯУЛ FINAL REPORT
=================================================================
тЪая╕П  р╕Юр╕Ър╕Ыр╕▒р╕Нр╕лр╕▓р╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф: 5

ЁЯФ┤ Priority Issues:
   1. р╕ер╕Ъ constant features
   2. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ data leakage features
   3. р╕Ир╕▒р╕Фр╕Бр╕▓р╕г multicollinearity

ЁЯОп Recommended Next Steps:
   1. ЁЯеЗ LightGBM / XGBoost
   2. р╣Гр╕Кр╣Й cross-validation р╣Ар╕Юр╕╖р╣Ир╕нр╕Ыр╕гр╕░р╣Ар╕бр╕┤р╕Щр╣Вр╕бр╣Ар╕Фр╕е
   3. Plot learning curves р╣Ар╕Юр╕╖р╣Ир╕нр╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ overfitting
```

---

### 8. ЁЯОп **Feature Importance Analysis**
```python
from kaggle_utils.diagnostics import analyze_feature_importance_detailed

# р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М feature importance р╣Бр╕Ър╕Ър╕ер╕░р╣Ар╕нр╕╡р╕вр╕Ф
importance_df = analyze_feature_importance_detailed(
    model=trained_model,
    X=X_train,
    y=y_train,
    feature_names=X_train.columns,
    top_n=20
)
```

**р╣Бр╕кр╕Фр╕З:**
- ЁЯУК Built-in feature importance
- ЁЯФД Permutation importance (р╣Бр╕бр╣Ир╕Щр╕вр╕│р╕Бр╕зр╣Ир╕▓)
- ЁЯТб р╣Бр╕Щр╕░р╕Щр╕│ features р╕Чр╕╡р╣Ир╕Др╕зр╕гр╕ер╕Ъ

---

## ЁЯТб р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щр╕Ир╕гр╕┤р╕З

### Example 1: р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╣Вр╕Ыр╕гр╣Ар╕Ир╕Др╣Гр╕лр╕бр╣И
```python
from kaggle_utils.diagnostics import quick_diagnosis
from kaggle_utils.preprocessing import reduce_mem_usage

# 1. р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕е
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

# 2. р╕ер╕Ф memory
train = reduce_mem_usage(train)
test = reduce_mem_usage(test)

# 3. р╕зр╕┤р╕Щр╕┤р╕Ир╕Йр╕▒р╕вр╕Фр╣Ир╕зр╕Щ
report = quick_diagnosis(
    train_df=train,
    target_col='target',
    test_df=test
)

# 4. р╕Фр╕│р╣Ар╕Щр╕┤р╕Щр╕Бр╕▓р╕гр╕Хр╕▓р╕бр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│
# - р╕ер╕Ъ constant features
# - р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ data leakage
# - р╣Ар╕ер╕╖р╕нр╕Бр╣Вр╕бр╣Ар╕Фр╕ер╕Хр╕▓р╕бр╕Чр╕╡р╣Ир╣Бр╕Щр╕░р╕Щр╕│
```

### Example 2: р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Бр╣Ир╕нр╕Щ Submit
```python
from kaggle_utils.diagnostics import (
    detect_leakage,
    detect_overfitting,
    plot_learning_curve
)
from sklearn.model_selection import train_test_split

# 1. Split data
X = train.drop(columns=['target'])
y = train['target']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ data leakage
suspicious = detect_leakage(train, 'target', test)

# 3. Train model
model.fit(X_train, y_train)

# 4. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ overfitting
overfitting_report = detect_overfitting(model, X_train, y_train, X_val, y_val)

# 5. Plot learning curve
plot_learning_curve(model, X, y, cv=5)

# р╕Цр╣Йр╕▓р╣Др╕бр╣Ир╕бр╕╡р╕Ыр╕▒р╕Нр╕лр╕▓ тЖТ Submit!
# р╕Цр╣Йр╕▓р╕бр╕╡р╕Ыр╕▒р╕Нр╕лр╕▓ тЖТ р╣Бр╕Бр╣Йр╣Др╕Вр╕Хр╕▓р╕бр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│
```

### Example 3: Feature Engineering Workflow
```python
from kaggle_utils.diagnostics import (
    check_multicollinearity,
    analyze_feature_importance_detailed
)

# 1. р╕кр╕гр╣Йр╕▓р╕З features р╣Гр╕лр╕бр╣И
train['feature_new'] = train['a'] * train['b']

# 2. р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ multicollinearity
high_corr = check_multicollinearity(train.drop(columns=['target']))

# 3. Train model
model.fit(X_train, y_train)

# 4. р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М feature importance
importance_df = analyze_feature_importance_detailed(
    model, X_train, y_train, X_train.columns
)

# 5. р╕ер╕Ъ features р╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕кр╕│р╕Др╕▒р╕Н
features_to_keep = importance_df[importance_df['importance'] > 0.001]['feature'].tolist()
X_train_selected = X_train[features_to_keep]
```

---

## ЁЯОп р╣Ар╕бр╕╖р╣Ир╕нр╣Др╕лр╕гр╣Ир╕Др╕зр╕гр╣Гр╕Кр╣Йр╕Яр╕▒р╕Зр╕Бр╣Мр╕Кр╕▒р╕Щр╣Др╕лр╕Щ?

| р╕кр╕Цр╕▓р╕Щр╕Бр╕▓р╕гр╕Ур╣М | р╕Яр╕▒р╕Зр╕Бр╣Мр╕Кр╕▒р╕Щр╕Чр╕╡р╣Ир╣Бр╕Щр╕░р╕Щр╕│ |
|-----------|------------------|
| ЁЯЖХ р╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╣Вр╕Ыр╕гр╣Ар╕Ир╕Др╣Гр╕лр╕бр╣И | `quick_diagnosis()` |
| ЁЯФН р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕╕р╕Ур╕ар╕▓р╕Юр╕Вр╣Йр╕нр╕бр╕╣р╕е | `check_data_quality()` |
| ЁЯЪи р╕кр╕Зр╕кр╕▒р╕вр╕зр╣Ир╕▓р╕бр╕╡ data leakage | `detect_leakage()` |
| ЁЯдЦ р╣Др╕бр╣Ир╕гр╕╣р╣Йр╕Ир╕░р╣Гр╕Кр╣Йр╣Вр╕бр╣Ар╕Фр╕ер╣Др╕лр╕Щ | `suggest_models()` |
| ЁЯУК Train/Val score р╕лр╣Ир╕▓р╕Зр╕Бр╕▒р╕Щр╕бр╕▓р╕Б | `detect_overfitting()` |
| ЁЯУИ р╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕гр╕Фр╕╣ learning curve | `plot_learning_curve()` |
| ЁЯОп р╣Ар╕ер╕╖р╕нр╕Б features | `analyze_feature_importance_detailed()` |
| ЁЯФЧ Features р╕лр╕ер╕▓р╕вр╕Хр╕▒р╕зр╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щ | `check_multicollinearity()` |

---

## тЪая╕П р╕Др╕│р╣Ар╕Хр╕╖р╕нр╕Щр╕кр╕│р╕Др╕▒р╕Н

### Data Leakage р╕Др╕╖р╕нр╕нр╕░р╣Др╕г?
- Features р╕Чр╕╡р╣Ир╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕▓р╕Бр╕нр╕Щр╕▓р╕Др╕Х (р╕гр╕╣р╣Йр╕Др╕│р╕Хр╕нр╕Ър╕Бр╣Ир╕нр╕Щ)
- Features р╕Чр╕╡р╣Ир╕Др╕│р╕Щр╕зр╕Ур╕Ир╕▓р╕Б target р╣Вр╕Фр╕вр╕Хр╕гр╕З
- Test data р╕гр╕▒р╣Ир╕зр╣Др╕лр╕ер╣Ар╕Вр╣Йр╕▓ training set

**р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З:**
```python
# тЭМ WRONG - Data Leakage!
train['price_mean'] = train.groupby('category')['price'].transform('mean')
# тЖР р╣Гр╕Кр╣Йр╕Др╣Ир╕▓р╣Ар╕Йр╕ер╕╡р╣Ир╕вр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф р╕гр╕зр╕бр╕Цр╕╢р╕З future data

# тЬЕ CORRECT
train['price_mean'] = train.groupby('category')['price'].transform(
    lambda x: x.expanding().mean().shift()
)
# тЖР р╣Гр╕Кр╣Йр╣Бр╕Др╣Ир╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Бр╣Ир╕нр╕Щр╕лр╕Щр╣Йр╕▓
```

### Overfitting vs Underfitting

**Overfitting:**
- Train score р╕Фр╕╡р╕бр╕▓р╕Б р╣Бр╕Хр╣И Val score р╣Бр╕вр╣И
- Model р╕Ир╕│р╕Вр╣Йр╕нр╕бр╕╣р╕е training р╣Бр╕Чр╕Щр╕Чр╕╡р╣Ир╕Ир╕░р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Й pattern
- р╣Бр╕Бр╣Й: Regularization, р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е, р╕ер╕Ф complexity

**Underfitting:**
- р╕Чр╕▒р╣Йр╕З Train р╣Бр╕ер╕░ Val score р╣Бр╕вр╣Ир╕Чр╕▒р╣Йр╕Зр╕Др╕╣р╣И
- Model р╕Зр╣Ир╕▓р╕вр╣Ар╕Бр╕┤р╕Щр╣Др╕Ы р╕Ир╕▒р╕Ъ pattern р╣Др╕бр╣Ир╣Др╕Фр╣Й
- р╣Бр╕Бр╣Й: р╣Ар╕Юр╕┤р╣Ир╕б complexity, р╣Ар╕Юр╕┤р╣Ир╕б features

---

## ЁЯЪА Integration р╕Бр╕▒р╕Ъ Workflow

```python
from kaggle_utils import *
from kaggle_utils.diagnostics import quick_diagnosis

# 1. Setup
setup_colab()

# 2. Load & Inspect
train = pd.read_csv('train.csv')
quick_info(train)

# 3. Comprehensive Diagnosis
report = quick_diagnosis(train, target_col='target', test_df=test)

# 4. Clean Data (р╕Хр╕▓р╕бр╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│)
train = train.drop(columns=report['quality_report']['constant_features'])

# 5. Train Models
rf = RandomForestWrapper(n_splits=5)
rf.train(X_train, y_train, X_test)

# 6. Check Overfitting
detect_overfitting(rf.models[0], X_train, y_train, X_val, y_val)

# 7. Submit
create_submission(test['id'], rf.test_predictions, 'submission.csv')
```

---

## ЁЯУЦ р╣Ар╕Юр╕┤р╣Ир╕бр╣Ар╕Хр╕┤р╕б

р╕Фр╕╣ examples р╣Гр╕Щ `examples/` folder:
- `example_diagnostics.ipynb` - р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щр╣Бр╕Ър╕Ър╕ер╕░р╣Ар╕нр╕╡р╕вр╕Ф
- `example_beginner_workflow.ipynb` - Workflow р╕кр╕│р╕лр╕гр╕▒р╕Ър╕бр╕╖р╕нр╣Гр╕лр╕бр╣И

---

**ЁЯТб Pro Tip:** р╣Гр╕Кр╣Й `quick_diagnosis()` р╕Бр╣Ир╕нр╕Щр╣Ар╕кр╕бр╕нр╣Ар╕бр╕╖р╣Ир╕нр╣Ар╕гр╕┤р╣Ир╕бр╣Вр╕Ыр╕гр╣Ар╕Ир╕Др╣Гр╕лр╕бр╣И!
