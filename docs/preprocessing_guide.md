# üìñ Preprocessing Module - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

## üìö ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô

### 1. üîç Data Inspection
- `quick_info()` - ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ
- `reduce_mem_usage()` - ‡∏•‡∏î memory usage

### 2. üõ†Ô∏è Missing Values
- `handle_missing_values()` - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values
- `create_missing_indicators()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á binary features ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ missing ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

### 3. üî¢ Encoding
- `encode_categorical()` - Encode categorical features
- `target_encode()` - Target encoding with smoothing

### 4. ‚öñÔ∏è Scaling
- `scale_features()` - Scale numeric features

### 5. üéØ Feature Engineering
- `create_time_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏à‡∏≤‡∏Å‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
- `create_polynomial_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á polynomial features (x¬≤, x*y)
- `create_interaction_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á interactions (multiply, divide, etc.)
- `create_aggregation_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á group-by statistics
- `create_ratio_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á ratio features
- `create_bins()` - ‡πÅ‡∏ö‡πà‡∏á continuous ‡πÄ‡∏õ‡πá‡∏ô categorical
- `create_text_features()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏à‡∏≤‡∏Å text

### 6. ‚úÇÔ∏è Feature Selection
- `auto_feature_selection()` - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å features ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- `remove_low_variance_features()` - ‡∏•‡∏ö features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏ï‡πà‡∏≥

### 7. üïê Time Series
- `split_train_test_by_date()` - ‡πÅ‡∏ö‡πà‡∏á train/test ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤

---

## üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### Example 1: Basic Workflow
```python
from kaggle_utils.preprocessing import *

# 1. ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
quick_info(train, "Training Data")

# 2. ‡∏•‡∏î memory
train = reduce_mem_usage(train)

# 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values (auto)
train = handle_missing_values(train, strategy='auto')

# 4. Encode categorical
train = encode_categorical(train, method='label')

# 5. Scale features
train_scaled, scaler = scale_features(train, method='standard')
```

### Example 2: Missing Values Handling
```python
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Auto (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
train = handle_missing_values(train, strategy='auto')
# numeric ‚Üí median, categorical ‚Üí mode

# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏•‡∏ö columns + rows
train = handle_missing_values(train, strategy='drop', threshold=0.5)
# ‡∏•‡∏ö columns ‡∏ó‡∏µ‡πà‡∏°‡∏µ missing > 50%, ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏ö rows ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠

# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á indicator features (‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á missing ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢!)
train = create_missing_indicators(train, columns=['price', 'area'])
# ‡∏™‡∏£‡πâ‡∏≤‡∏á 'price_is_missing', 'area_is_missing'
train = handle_missing_values(train, strategy='median')
```

### Example 3: Encoding Categorical Features
```python
# Label Encoding (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö tree-based models)
train = encode_categorical(train, method='label')

# One-Hot Encoding (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö linear models)
train = encode_categorical(train, method='onehot', drop_first=True)

# Frequency Encoding
train = encode_categorical(train, method='frequency')

# Target Encoding (‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏ï‡πà‡∏£‡∏∞‡∏ß‡∏±‡∏á overfitting)
train, test = target_encode(
    train, test, 
    cat_cols=['category', 'brand'],
    target_col='price',
    smoothing=10  # ‡πÄ‡∏û‡∏¥‡πà‡∏° smoothing ‡∏ñ‡πâ‡∏≤‡∏Å‡∏•‡∏±‡∏ß overfitting
)
```

### Example 4: Time Features (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!)
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á 17 time features ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
train = create_time_features(train, date_col='purchase_date', drop_original=False)

# Features ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:
# - year, month, day, dayofweek, dayofyear, quarter, week
# - month_sin, month_cos, day_sin, day_cos (cyclical encoding)
# - is_weekend, is_month_start, is_month_end
# - is_quarter_start, is_quarter_end
```

### Example 5: Feature Engineering
```python
# Polynomial Features
X_poly = create_polynomial_features(X, degree=2, interaction_only=False)
# ‡∏™‡∏£‡πâ‡∏≤‡∏á: x¬≤, y¬≤, x*y, etc.

# Interaction Features (manual control)
train = create_interaction_features(
    train,
    col_pairs=[('price', 'area'), ('age', 'rooms')],
    operation='multiply'
)

# Aggregation Features (group statistics)
train = create_aggregation_features(
    train,
    group_cols=['city', 'category'],
    agg_cols=['price', 'area'],
    agg_funcs=['mean', 'std', 'min', 'max']
)
# ‡∏™‡∏£‡πâ‡∏≤‡∏á: price_mean_by_city_category, price_std_by_city_category, etc.

# Ratio Features
train = create_ratio_features(
    train,
    numerator_cols=['price'],
    denominator_cols=['area', 'rooms']
)
# ‡∏™‡∏£‡πâ‡∏≤‡∏á: price_per_area, price_per_rooms
```

### Example 6: Text Features
```python
# ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ text column
train = create_text_features(train, text_col='description')

# Features ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:
# - description_length (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß)
# - description_word_count (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥)
# - description_unique_words (‡∏Ñ‡∏≥‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
# - description_uppercase_count
# - description_digit_count
# - description_special_char_count
```

### Example 7: Feature Selection
```python
# Auto selection
selected_features = auto_feature_selection(
    X_train, y_train,
    k=30,  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 30 features
    task='auto',  # auto-detect regression/classification
    method='both'  # ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á F-test ‡πÅ‡∏•‡∏∞ Mutual Information
)

X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

# Remove low variance
train = remove_low_variance_features(train, threshold=0.01)
```

### Example 8: Binning (‡πÅ‡∏ö‡πà‡∏á‡∏ä‡πà‡∏ß‡∏á)
```python
# ‡πÅ‡∏ö‡πà‡∏á age ‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏Å‡∏•‡∏∏‡πà‡∏°
train = create_bins(
    train, 
    column='age',
    n_bins=5,
    labels=['very_young', 'young', 'middle', 'old', 'very_old'],
    strategy='quantile'  # ‡πÅ‡∏ö‡πà‡∏á‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
)
```

---

## üéØ Complete Workflow Example

```python
from kaggle_utils.preprocessing import *
import pandas as pd

# === 1. LOAD DATA ===
train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')
target_col = 'price'

# === 2. INSPECT ===
quick_info(train, "Training Data")
quick_info(test, "Test Data")

# === 3. REDUCE MEMORY ===
train = reduce_mem_usage(train)
test = reduce_mem_usage(test)

# === 4. HANDLE MISSING VALUES ===
# ‡∏™‡∏£‡πâ‡∏≤‡∏á missing indicators ‡∏Å‡πà‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤ missing ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢)
train = create_missing_indicators(train, columns=['area', 'rooms'])
test = create_missing_indicators(test, columns=['area', 'rooms'])

# ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ fill missing
train = handle_missing_values(train, strategy='auto')
test = handle_missing_values(test, strategy='auto')

# === 5. TIME FEATURES ===
if 'purchase_date' in train.columns:
    train = create_time_features(train, 'purchase_date')
    test = create_time_features(test, 'purchase_date')

# === 6. TEXT FEATURES ===
if 'description' in train.columns:
    train = create_text_features(train, 'description')
    test = create_text_features(test, 'description')

# === 7. FEATURE ENGINEERING ===
# Interaction features
train = create_interaction_features(
    train,
    col_pairs=[('area', 'rooms'), ('age', 'floor')],
    operation='multiply'
)
test = create_interaction_features(
    test,
    col_pairs=[('area', 'rooms'), ('age', 'floor')],
    operation='multiply'
)

# Aggregation features
train = create_aggregation_features(
    train,
    group_cols=['city'],
    agg_cols=['price', 'area'],
    agg_funcs=['mean', 'std']
)
test = create_aggregation_features(
    test,
    group_cols=['city'],
    agg_cols=['price', 'area'],
    agg_funcs=['mean', 'std']
)

# === 8. ENCODING ===
# Label encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical
cat_cols = train.select_dtypes(include=['object']).columns.tolist()
cat_cols = [c for c in cat_cols if c != target_col]

train = encode_categorical(train, method='label', columns=cat_cols)
test = encode_categorical(test, method='label', columns=cat_cols)

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ target encoding (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏£‡∏∞‡∏ß‡∏±‡∏á overfitting)
# train, test = target_encode(
#     train, test,
#     cat_cols=['category', 'city'],
#     target_col=target_col,
#     smoothing=10
# )

# === 9. FEATURE SELECTION ===
X = train.drop(columns=[target_col])
y = train[target_col]

# Remove low variance
X = remove_low_variance_features(X, threshold=0.01)

# Auto selection
selected_features = auto_feature_selection(X, y, k=50, method='both')
X_selected = X[selected_features]
X_test_selected = test[selected_features]

# === 10. SCALING (optional - ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö linear models) ===
# X_selected, scaler = scale_features(X_selected, method='standard')
# X_test_selected, _ = scale_features(X_test_selected, method='standard')

print(f"\n‚úÖ Preprocessing Complete!")
print(f"Final shape: {X_selected.shape}")
```

---

## üö® Tips & Best Practices

### ‚ö†Ô∏è Data Leakage Prevention

**‚ùå WRONG - Data Leakage:**
```python
# ‡∏´‡πâ‡∏≤‡∏°! Target encoding ‡∏Å‡πà‡∏≠‡∏ô split
df = target_encode(df, ['category'], 'price')
train, val = train_test_split(df)
```

**‚úÖ CORRECT:**
```python
# Split ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ encode
train, val = train_test_split(df)
train, val = target_encode(train, val, ['category'], 'price')
```

### üéØ Feature Engineering Order

**‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏•‡∏≥‡∏î‡∏±‡∏ö:**
1. Handle missing values
2. Create time features (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
3. Create domain-specific features
4. Create interaction/aggregation features
5. Encoding categorical
6. Feature selection
7. Scaling (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)

### üí° Target Encoding Tips

```python
# ‡πÉ‡∏ä‡πâ smoothing ‡∏™‡∏π‡∏á‡πÜ ‡∏ñ‡πâ‡∏≤:
# - Categories ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢
# - ‡∏Å‡∏•‡∏±‡∏ß overfitting

train, test = target_encode(
    train, test,
    cat_cols=['rare_category'],
    target_col='price',
    smoothing=100  # ‡∏™‡∏π‡∏á = ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting
)
```

### üîÑ Cyclical Encoding

**‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö time features!**
```python
# ‚ùå WRONG - Model ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤ month=12 ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö month=1
df['month'] = df['date'].dt.month

# ‚úÖ CORRECT - Cyclical encoding
df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)
df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)
```

### üìä When to Scale?

**‡∏ï‡πâ‡∏≠‡∏á Scale:**
- Linear models (Ridge, Lasso, Logistic)
- Neural Networks
- SVM
- K-Nearest Neighbors

**‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á Scale:**
- Tree-based models (Random Forest, XGBoost, LightGBM)
- Naive Bayes

---

## üîó Integration with Other Modules

```python
from kaggle_utils import *
from kaggle_utils.preprocessing import *
from kaggle_utils.diagnostics import quick_diagnosis

# 1. Preprocess
train = reduce_mem_usage(train)
train = handle_missing_values(train, strategy='auto')

# 2. Diagnose
report = quick_diagnosis(train, target_col='price')

# 3. Feature Engineering (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å report)
if 'purchase_date' in train.columns:
    train = create_time_features(train, 'purchase_date')

# 4. Train Model
lgb = LGBWrapper(n_splits=5)
lgb.train(X_train, y_train, X_test)
```

---

## üìå Quick Reference

| Task | Function | Example |
|------|----------|---------|
| ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | `quick_info()` | `quick_info(train)` |
| ‡∏•‡∏î memory | `reduce_mem_usage()` | `train = reduce_mem_usage(train)` |
| Fill missing | `handle_missing_values()` | `train = handle_missing_values(train, 'auto')` |
| Encode | `encode_categorical()` | `train = encode_categorical(train, 'label')` |
| Scale | `scale_features()` | `train, scaler = scale_features(train, 'standard')` |
| Time features | `create_time_features()` | `train = create_time_features(train, 'date')` |
| Interactions | `create_interaction_features()` | `train = create_interaction_features(train, [('a','b')])` |
| Aggregations | `create_aggregation_features()` | `train = create_aggregation_features(train, ['city'], ['price'])` |
| Feature selection | `auto_feature_selection()` | `features = auto_feature_selection(X, y, k=30)` |

---

**üí° Pro Tip:** ‡πÉ‡∏ä‡πâ `quick_info()` ‡∏ö‡πà‡∏≠‡∏¢‡πÜ ‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£!
