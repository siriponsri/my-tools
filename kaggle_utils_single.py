"""
üöÄ Kaggle Utils - Single File Version
‡∏ä‡∏∏‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡∏´‡∏±‡∏î‡πÅ‡∏Ç‡πà‡∏á Kaggle (‡∏£‡∏ß‡∏°‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)

Quick Start:
    !wget https://raw.githubusercontent.com/siriponsri/my-tools/main/kaggle_utils_single.py
    from kaggle_utils_single import *

Version: 1.0.0
License: MIT
"""

import os
import warnings
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Optional, Union, List, Any, Dict

warnings.filterwarnings('ignore')

__version__ = '1.0.0'
__all__ = [
    # Data
    'quick_info',
    'reduce_mem_usage',
    'load_data',
    'save_data',
    
    # Models
    'quick_model_comparison',
    
    # Utils
    'setup_colab',
    'setup_kaggle',
    'create_submission',
    'set_seed',
    
    # Diagnostics
    'check_data_quality',
    'detect_leakage',
    'quick_diagnosis',
]


# ============================================================
# DATA INSPECTION & PREPROCESSING
# ============================================================

def quick_info(df: pd.DataFrame, name: str = "DataFrame"):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡∏≠‡∏á DataFrame
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
    name : str
        ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á DataFrame
    
    Returns:
    --------
    pd.DataFrame
        ‡πÅ‡∏™‡∏î‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
    """
    print(f"\n{'='*60}")
    print(f"üìä {name} Information")
    print(f"{'='*60}")
    print(f"Shape: {df.shape[0]:,} rows √ó {df.shape[1]:,} columns")
    print(f"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    print(f"\nüîç Missing Values:")
    missing = df.isnull().sum()
    missing_pct = 100 * missing / len(df)
    missing_df = pd.DataFrame({
        'Missing': missing[missing > 0],
        'Percent': missing_pct[missing > 0]
    }).sort_values('Missing', ascending=False)
    
    if len(missing_df) > 0:
        print(missing_df)
    else:
        print("No missing values! üéâ")
    
    print(f"\nüìà Data Types:")
    print(df.dtypes.value_counts())
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    categorical_cols = df.select_dtypes(include=['object']).columns
    print(f"\nNumeric features: {len(numeric_cols)}")
    print(f"Categorical features: {len(categorical_cols)}")
    
    print(f"\nüíæ First few rows:")
    return df.head()


def reduce_mem_usage(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:
    """
    ‡∏•‡∏î memory usage ‡∏Ç‡∏≠‡∏á DataFrame
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏î memory
    verbose : bool
        ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    
    Returns:
    --------
    pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡∏•‡∏î memory ‡πÅ‡∏•‡πâ‡∏ß
    """
    start_mem = df.memory_usage().sum() / 1024**2
    
    for col in df.columns:
        col_type = df[col].dtype
        
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float32)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    
    end_mem = df.memory_usage().sum() / 1024**2
    
    if verbose:
        print(f'üíæ Memory usage decreased from {start_mem:.2f} MB to {end_mem:.2f} MB '
              f'({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')
    
    return df


def load_data(filepath: str, encoding: str = 'utf-8', show_info: bool = False, **kwargs) -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ format)
    
    Parameters:
    -----------
    filepath : str
        Path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
    encoding : str
        Encoding ('utf-8', 'latin1', 'auto')
    show_info : bool
        ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á load
    **kwargs
        ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á pandas.read_*
    
    Returns:
    --------
    pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß
    """
    file_ext = Path(filepath).suffix.lower()
    
    try:
        if file_ext == '.csv':
            df = pd.read_csv(filepath, encoding=encoding, **kwargs)
        elif file_ext in ['.parquet', '.pq']:
            df = pd.read_parquet(filepath, **kwargs)
        elif file_ext in ['.xlsx', '.xls']:
            df = pd.read_excel(filepath, **kwargs)
        elif file_ext == '.json':
            df = pd.read_json(filepath, **kwargs)
        elif file_ext == '.feather':
            df = pd.read_feather(filepath, **kwargs)
        elif file_ext in ['.pickle', '.pkl']:
            df = pd.read_pickle(filepath, **kwargs)
        else:
            raise ValueError(f"Unsupported file format: {file_ext}")
        
        print(f"‚úÖ Loaded {filepath}")
        print(f"   Shape: {df.shape[0]:,} rows √ó {df.shape[1]:,} columns")
        
        if show_info:
            quick_info(df, Path(filepath).name)
        
        return df
    
    except Exception as e:
        print(f"‚ùå Error loading {filepath}: {e}")
        raise


def save_data(df: pd.DataFrame, filepath: str, **kwargs):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (auto detect format)
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    filepath : str
        Path ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    **kwargs
        ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á pandas.to_*
    """
    file_ext = Path(filepath).suffix.lower()
    
    try:
        if file_ext == '.csv':
            df.to_csv(filepath, index=False, **kwargs)
        elif file_ext in ['.parquet', '.pq']:
            df.to_parquet(filepath, **kwargs)
        elif file_ext in ['.xlsx', '.xls']:
            df.to_excel(filepath, index=False, **kwargs)
        elif file_ext == '.json':
            df.to_json(filepath, **kwargs)
        elif file_ext == '.feather':
            df.to_feather(filepath, **kwargs)
        elif file_ext in ['.pickle', '.pkl']:
            df.to_pickle(filepath, **kwargs)
        else:
            raise ValueError(f"Unsupported file format: {file_ext}")
        
        file_size = os.path.getsize(filepath) / 1024**2
        print(f"‚úÖ Saved to {filepath}")
        print(f"   Size: {file_size:.2f} MB")
    
    except Exception as e:
        print(f"‚ùå Error saving {filepath}: {e}")
        raise


# ============================================================
# MODELS
# ============================================================

def quick_model_comparison(X, y, cv: int = 5, task: str = 'auto', verbose: bool = True):
    """
    ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏´‡∏•‡∏≤‡∏¢ models ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß
    
    Parameters:
    -----------
    X : pd.DataFrame or np.array
        Features
    y : pd.Series or np.array
        Target
    cv : int
        ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô CV folds
    task : str
        'auto', 'regression', 'classification'
    verbose : bool
        ‡πÅ‡∏™‡∏î‡∏á progress
    
    Returns:
    --------
    pd.DataFrame
        ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    """
    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
    from sklearn.linear_model import Ridge, LogisticRegression
    
    # Auto detect task
    if task == 'auto':
        if len(np.unique(y)) <= 20:
            task = 'classification'
        else:
            task = 'regression'
    
    if verbose:
        print(f"üîç Comparing models ({task})...")
        print(f"{'='*60}")
    
    results = []
    
    if task == 'regression':
        models = {
            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
            'Ridge': Ridge(random_state=42),
        }
        scoring = 'neg_mean_squared_error'
    else:
        models = {
            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        }
        scoring = 'accuracy'
    
    for name, model in models.items():
        if verbose:
            print(f"\nüìä {name}...")
        
        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)
        
        if task == 'regression':
            scores = np.sqrt(-scores)  # RMSE
        
        results.append({
            'Model': name,
            'Mean': scores.mean(),
            'Std': scores.std(),
            'Min': scores.min(),
            'Max': scores.max()
        })
        
        if verbose:
            print(f"   Score: {scores.mean():.4f} ¬± {scores.std():.4f}")
    
    results_df = pd.DataFrame(results).sort_values('Mean', ascending=(task=='regression'))
    
    if verbose:
        print(f"\n{'='*60}")
        print("üìà Results Summary:")
        print(results_df.to_string(index=False))
        print(f"\nüèÜ Best Model: {results_df.iloc[0]['Model']}")
    
    return results_df


# ============================================================
# UTILS
# ============================================================

def setup_colab():
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Colab environment"""
    try:
        from google.colab import drive
        
        print("="*60)
        print("üöÄ Setting up Google Colab")
        print("="*60)
        
        print("\nüìÅ Mounting Google Drive...")
        drive.mount('/content/drive')
        print("‚úÖ Drive mounted at: /content/drive")
        
        print("\n" + "="*60)
        print("‚úÖ Colab setup complete!")
        print("="*60)
        
    except ImportError:
        print("‚ö†Ô∏è  Not running in Google Colab")


def setup_kaggle(kaggle_json_path: Optional[str] = None):
    """
    ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Kaggle API
    
    Parameters:
    -----------
    kaggle_json_path : str, optional
        Path to kaggle.json file
    """
    print("="*60)
    print("üîë Setting up Kaggle API")
    print("="*60)
    
    kaggle_dir = Path.home() / '.kaggle'
    kaggle_dir.mkdir(exist_ok=True)
    
    if kaggle_json_path is None:
        possible_paths = [
            Path.home() / '.kaggle' / 'kaggle.json',
            Path('/content/drive/MyDrive/kaggle.json'),
            Path('kaggle.json')
        ]
        
        kaggle_json_path = None
        for path in possible_paths:
            if path.exists():
                kaggle_json_path = path
                break
    
    if kaggle_json_path is None:
        print("‚ùå kaggle.json not found!")
        print("\nüìù To set up:")
        print("1. Go to https://www.kaggle.com/")
        print("2. Account ‚Üí Create New API Token")
        print("3. Download kaggle.json")
        return
    
    import shutil
    target_path = kaggle_dir / 'kaggle.json'
    if kaggle_json_path != target_path:
        shutil.copy(kaggle_json_path, target_path)
    
    os.chmod(target_path, 0o600)
    
    print(f"‚úÖ Kaggle API configured!")
    print(f"   Config file: {target_path}")


def create_submission(
    ids,
    predictions,
    filename: str = 'submission.csv',
    id_column: str = 'id',
    target_column: str = 'target',
    show_sample: bool = True
):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå submission
    
    Parameters:
    -----------
    ids : array-like
        ID column
    predictions : array-like
        Predictions
    filename : str
        ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    id_column : str
        ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID
    target_column : str
        ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö prediction
    show_sample : bool
        ‡πÅ‡∏™‡∏î‡∏á sample ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    submission = pd.DataFrame({
        id_column: ids,
        target_column: predictions
    })
    
    submission.to_csv(filename, index=False)
    
    file_size = os.path.getsize(filename) / 1024
    
    print(f"‚úÖ Submission file created: {filename}")
    print(f"üìä Shape: {submission.shape}")
    print(f"üíæ Size: {file_size:.2f} KB")
    
    if show_sample:
        print(f"\nSample:")
        print(submission.head())


def set_seed(seed: int = 42):
    """
    ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ random seed
    
    Parameters:
    -----------
    seed : int
        Random seed
    """
    import random
    random.seed(seed)
    np.random.seed(seed)
    
    try:
        import torch
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    except ImportError:
        pass
    
    try:
        import tensorflow as tf
        tf.random.set_seed(seed)
    except ImportError:
        pass
    
    print(f"‚úÖ Random seed set to {seed}")


# ============================================================
# DIAGNOSTICS
# ============================================================

def check_data_quality(df: pd.DataFrame, target_col: Optional[str] = None, show_details: bool = True):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    Parameters:
    -----------
    df : pd.DataFrame
        DataFrame ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
    target_col : str, optional
        ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏Ç‡∏≠‡∏á target
    show_details : bool
        ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    
    Returns:
    --------
    dict
        ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    """
    print("="*70)
    print("üîç DATA QUALITY CHECK")
    print("="*70)
    
    issues = []
    suggestions = []
    
    # 1. Missing Values
    missing = df.isnull().sum()
    missing_pct = 100 * missing / len(df)
    high_missing = missing_pct[missing_pct > 50]
    
    if len(high_missing) > 0:
        issues.append(f"‚ö†Ô∏è  {len(high_missing)} features ‡∏°‡∏µ missing > 50%")
        suggestions.append(f"üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏•‡∏ö features: {list(high_missing.index[:3])}")
        if show_details:
            print(f"\nüìä High missing values (>50%):")
            print(high_missing.head())
    
    # 2. Constant Features
    constant_features = []
    for col in df.columns:
        if df[col].dtype != 'object' and df[col].nunique() == 1:
            constant_features.append(col)
    
    if constant_features:
        issues.append(f"‚ö†Ô∏è  {len(constant_features)} constant features")
        suggestions.append(f"üí° ‡∏•‡∏ö constant features")
    
    # 3. High Cardinality
    cat_cols = df.select_dtypes(include=['object']).columns
    high_cardinality = []
    for col in cat_cols:
        unique_ratio = df[col].nunique() / len(df)
        if unique_ratio > 0.5:
            high_cardinality.append(col)
    
    if high_cardinality:
        issues.append(f"‚ö†Ô∏è  {len(high_cardinality)} features ‡∏°‡∏µ cardinality ‡∏™‡∏π‡∏á")
        suggestions.append("üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÉ‡∏ä‡πâ target encoding")
    
    # 4. Target Distribution
    if target_col and target_col in df.columns:
        print(f"\nüìä Target Distribution ({target_col}):")
        if df[target_col].dtype == 'object' or df[target_col].nunique() < 20:
            print(df[target_col].value_counts().head())
        else:
            print(df[target_col].describe())
    
    # Summary
    print(f"\n{'='*70}")
    print(f"üìã SUMMARY")
    print(f"{'='*70}")
    print(f"Issues found: {len(issues)}")
    for issue in issues:
        print(issue)
    
    print(f"\nüí° SUGGESTIONS:")
    for suggestion in suggestions:
        print(suggestion)
    
    return {
        'issues': issues,
        'suggestions': suggestions,
        'high_missing': list(high_missing.index) if len(high_missing) > 0 else [],
        'constant_features': constant_features,
        'high_cardinality': high_cardinality
    }


def detect_leakage(train_df: pd.DataFrame, target_col: str, test_df: Optional[pd.DataFrame] = None):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö data leakage
    
    Parameters:
    -----------
    train_df : pd.DataFrame
        Training data
    target_col : str
        Target column
    test_df : pd.DataFrame, optional
        Test data
    
    Returns:
    --------
    list
        Features ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢
    """
    print("="*70)
    print("üîç DATA LEAKAGE DETECTION")
    print("="*70)
    
    suspicious_features = []
    
    # Check correlation with target
    numeric_cols = train_df.select_dtypes(include=[np.number]).columns
    numeric_cols = [col for col in numeric_cols if col != target_col]
    
    if target_col in train_df.columns and len(numeric_cols) > 0:
        correlations = train_df[numeric_cols].corrwith(train_df[target_col]).abs()
        high_corr = correlations[correlations > 0.95]
        
        if len(high_corr) > 0:
            print(f"\n‚ö†Ô∏è  Features with very high correlation (>0.95):")
            for col, corr in high_corr.items():
                print(f"   {col}: {corr:.4f}")
                suspicious_features.append(col)
    
    # Check train-test differences
    if test_df is not None:
        common_cols = set(train_df.columns) & set(test_df.columns)
        common_cols = [col for col in common_cols if col != target_col]
        
        print(f"\nüìä Train vs Test comparison:")
        for col in list(common_cols)[:5]:  # Check first 5
            if train_df[col].dtype in [np.number]:
                train_mean = train_df[col].mean()
                test_mean = test_df[col].mean()
                diff_pct = abs(train_mean - test_mean) / train_mean * 100
                
                if diff_pct > 50:
                    print(f"   ‚ö†Ô∏è  {col}: {diff_pct:.1f}% difference")
                    suspicious_features.append(col)
    
    if len(suspicious_features) == 0:
        print("\n‚úÖ No obvious leakage detected!")
    else:
        print(f"\n‚ö†Ô∏è  Found {len(suspicious_features)} suspicious features")
    
    return list(set(suspicious_features))


def quick_diagnosis(train_df: pd.DataFrame, target_col: str, test_df: Optional[pd.DataFrame] = None):
    """
    ‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏à‡∏ö‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    
    Parameters:
    -----------
    train_df : pd.DataFrame
        Training data
    target_col : str
        Target column
    test_df : pd.DataFrame, optional
        Test data
    
    Returns:
    --------
    dict
        ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
    """
    print("\n" + "="*70)
    print("üè• KAGGLE UTILS - QUICK DIAGNOSIS")
    print("="*70)
    
    # 1. Data Quality
    quality_report = check_data_quality(train_df, target_col)
    
    # 2. Leakage Detection
    if test_df is not None:
        suspicious_features = detect_leakage(train_df, target_col, test_df)
    else:
        suspicious_features = []
    
    # 3. Recommendations
    print("\n" + "="*70)
    print("üéØ RECOMMENDED NEXT STEPS")
    print("="*70)
    
    print("\n1. ‚úÖ Data Cleaning:")
    if quality_report['high_missing']:
        print(f"   - Handle missing values in {len(quality_report['high_missing'])} features")
    if quality_report['constant_features']:
        print(f"   - Remove {len(quality_report['constant_features'])} constant features")
    
    print("\n2. üîß Feature Engineering:")
    print("   - Create interaction features")
    print("   - Use target encoding for high cardinality")
    
    print("\n3. ü§ñ Model Selection:")
    n_samples = len(train_df)
    n_features = train_df.shape[1]
    
    if n_samples < 10000:
        print("   - Try: Random Forest, LightGBM")
    else:
        print("   - Try: LightGBM, XGBoost (faster)")
    
    if suspicious_features:
        print(f"\n‚ö†Ô∏è  WARNING: {len(suspicious_features)} suspicious features detected!")
        print("   Please review before using them in your model.")
    
    return {
        'quality': quality_report,
        'suspicious_features': suspicious_features,
        'n_samples': n_samples,
        'n_features': n_features
    }


# ============================================================
# QUICK START EXAMPLE
# ============================================================

def example_usage():
    """‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
    print("""
    üöÄ KAGGLE UTILS - QUICK START
    
    # 1. Load data
    train = load_data('train.csv', show_info=True)
    test = load_data('test.csv')
    
    # 2. Diagnose
    report = quick_diagnosis(train, target_col='target', test_df=test)
    
    # 3. Reduce memory
    train = reduce_mem_usage(train)
    test = reduce_mem_usage(test)
    
    # 4. Compare models
    results = quick_model_comparison(X_train, y_train, cv=5)
    
    # 5. Create submission
    create_submission(test_ids, predictions, 'submission.csv')
    
    üìö Full documentation: https://github.com/YOUR_USERNAME/kaggle-utils
    """)


if __name__ == "__main__":
    print(f"Kaggle Utils v{__version__} loaded! üöÄ")
    print("Type: example_usage() to see quick start guide")
