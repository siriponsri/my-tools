"""
Data Validation and Interpretation Tools
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import learning_curve, validation_curve, cross_val_score
from sklearn.metrics import mean_squared_error, roc_auc_score
from sklearn.feature_selection import mutual_info_regression, mutual_info_classif
import warnings
warnings.filterwarnings('ignore')

# ==================== DATA QUALITY VALIDATION ====================

def check_data_quality(df, target_col=None, show_details=True):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: dictionary ‡∏Ç‡∏≠‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
    """
    print("="*70)
    print("üîç DATA QUALITY CHECK")
    print("="*70)
    
    issues = []
    warnings_list = []
    suggestions = []
    
    # 1. Missing Values
    missing = df.isnull().sum()
    missing_pct = 100 * missing / len(df)
    high_missing = missing_pct[missing_pct > 50]
    
    if len(high_missing) > 0:
        issues.append(f"‚ö†Ô∏è  {len(high_missing)} features ‡∏°‡∏µ missing values > 50%")
        suggestions.append(f"üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏•‡∏ö features: {list(high_missing.index)}")
        if show_details:
            print("\nüìä Features with high missing values (>50%):")
            print(high_missing.sort_values(ascending=False))
    
    # 2. Constant Features
    constant_features = []
    for col in df.columns:
        if df[col].dtype != 'object':
            if df[col].nunique() == 1:
                constant_features.append(col)
    
    if constant_features:
        issues.append(f"‚ö†Ô∏è  {len(constant_features)} features ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô)")
        suggestions.append(f"üí° ‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö constant features: {constant_features}")
        if show_details:
            print(f"\n‚ö†Ô∏è  Constant features: {constant_features}")
    
    # 3. Duplicate Features
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr().abs()
        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        duplicate_features = [column for column in upper.columns if any(upper[column] > 0.95)]
        
        if duplicate_features:
            issues.append(f"‚ö†Ô∏è  {len(duplicate_features)} features ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (>0.95)")
            suggestions.append(f"üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏•‡∏ö features ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô: {duplicate_features[:5]}")
            if show_details:
                print(f"\n‚ö†Ô∏è  Highly correlated features: {duplicate_features[:10]}")
    
    # 4. Cardinality Check (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö categorical)
    cat_cols = df.select_dtypes(include=['object']).columns
    high_cardinality = []
    for col in cat_cols:
        unique_ratio = df[col].nunique() / len(df)
        if unique_ratio > 0.5:
            high_cardinality.append((col, unique_ratio))
    
    if high_cardinality:
        warnings_list.append(f"‚ö†Ô∏è  {len(high_cardinality)} categorical features ‡∏°‡∏µ cardinality ‡∏™‡∏π‡∏á")
        suggestions.append("üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÉ‡∏ä‡πâ target encoding ‡∏´‡∏£‡∏∑‡∏≠ feature hashing")
        if show_details:
            print(f"\n‚ö†Ô∏è  High cardinality features:")
            for col, ratio in high_cardinality[:5]:
                print(f"   - {col}: {ratio:.1%} unique values")
    
    # 5. Target Distribution (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ target_col)
    if target_col and target_col in df.columns:
        print(f"\nüìä Target Distribution ({target_col}):")
        if df[target_col].dtype == 'object' or df[target_col].nunique() < 20:
            # Classification
            print(df[target_col].value_counts())
            class_balance = df[target_col].value_counts(normalize=True)
            if class_balance.min() < 0.1:
                issues.append("‚ö†Ô∏è  Class Imbalance ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö!")
                suggestions.append("üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÉ‡∏ä‡πâ SMOTE, class_weight, ‡∏´‡∏£‡∏∑‡∏≠ stratified sampling")
        else:
            # Regression
            print(f"Mean: {df[target_col].mean():.2f}")
            print(f"Std: {df[target_col].std():.2f}")
            print(f"Min: {df[target_col].min():.2f}")
            print(f"Max: {df[target_col].max():.2f}")
            
            # Check skewness
            skewness = df[target_col].skew()
            if abs(skewness) > 1:
                warnings_list.append(f"‚ö†Ô∏è  Target ‡∏°‡∏µ skewness ‡∏™‡∏π‡∏á ({skewness:.2f})")
                suggestions.append("üí° ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ log transform ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö target")
    
    # Summary
    print("\n" + "="*70)
    print("üìã SUMMARY")
    print("="*70)
    
    if not issues and not warnings_list:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ")
    else:
        print(f"\n‚ùå Issues found: {len(issues)}")
        for issue in issues:
            print(f"   {issue}")
        
        if warnings_list:
            print(f"\n‚ö†Ô∏è  Warnings: {len(warnings_list)}")
            for warning in warnings_list:
                print(f"   {warning}")
    
    if suggestions:
        print(f"\nüí° Suggestions:")
        for i, suggestion in enumerate(suggestions, 1):
            print(f"   {i}. {suggestion}")
    
    return {
        'issues': issues,
        'warnings': warnings_list,
        'suggestions': suggestions,
        'constant_features': constant_features,
        'high_missing_features': list(high_missing.index) if len(high_missing) > 0 else [],
        'duplicate_features': duplicate_features if 'duplicate_features' in locals() else []
    }

# ==================== DATA LEAKAGE DETECTION ====================

def detect_leakage(train_df, target_col, test_df=None, threshold=0.95):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Data Leakage ‡πÇ‡∏î‡∏¢‡∏´‡∏≤ features ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Å‡∏±‡∏ö target
    """
    print("="*70)
    print("üîç DATA LEAKAGE DETECTION")
    print("="*70)
    
    suspicious_features = []
    
    # 1. Perfect Correlation Check
    numeric_cols = train_df.select_dtypes(include=[np.number]).columns
    numeric_cols = [col for col in numeric_cols if col != target_col]
    
    if len(numeric_cols) > 0:
        correlations = train_df[numeric_cols + [target_col]].corr()[target_col].drop(target_col)
        high_corr = correlations[correlations.abs() > threshold]
        
        if len(high_corr) > 0:
            print(f"\n‚ö†Ô∏è  ‡∏û‡∏ö {len(high_corr)} features ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Å‡∏±‡∏ö target (>{threshold}):")
            for feat, corr in high_corr.items():
                print(f"   - {feat}: {corr:.4f}")
                suspicious_features.append(feat)
            print("\n‚ùå ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô Data Leakage! ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö features ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ")
    
    # 2. Mutual Information Check (‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)
    if train_df[target_col].dtype != 'object' and train_df[target_col].nunique() > 20:
        # Regression
        mi_scores = mutual_info_regression(train_df[numeric_cols], train_df[target_col])
    else:
        # Classification
        mi_scores = mutual_info_classif(train_df[numeric_cols], train_df[target_col])
    
    mi_df = pd.DataFrame({'feature': numeric_cols, 'mi_score': mi_scores})
    mi_df = mi_df.sort_values('mi_score', ascending=False)
    
    # Features ‡∏ó‡∏µ‡πà‡∏°‡∏µ MI ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ 3 ‡πÄ‡∏ó‡πà‡∏≤
    mean_mi = mi_df['mi_score'].mean()
    suspicious_mi = mi_df[mi_df['mi_score'] > 3 * mean_mi]
    
    if len(suspicious_mi) > 0:
        print(f"\n‚ö†Ô∏è  Features ‡∏ó‡∏µ‡πà‡∏°‡∏µ Mutual Information ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥:")
        print(suspicious_mi.head(10))
    
    # 3. Train-Test Distribution Check
    if test_df is not None:
        print("\nüîç Checking Train-Test Distribution Differences...")
        from scipy.stats import ks_2samp
        
        significant_diff = []
        for col in numeric_cols:
            if col in test_df.columns:
                stat, pvalue = ks_2samp(train_df[col].dropna(), test_df[col].dropna())
                if pvalue < 0.01:  # Significant difference
                    significant_diff.append((col, pvalue))
        
        if significant_diff:
            print(f"\n‚ö†Ô∏è  {len(significant_diff)} features ‡∏°‡∏µ distribution ‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á train-test:")
            for col, pval in significant_diff[:5]:
                print(f"   - {col}: p-value = {pval:.6f}")
            print("\nüí° ‡∏≠‡∏≤‡∏à‡∏°‡∏µ data leakage ‡∏´‡∏£‡∏∑‡∏≠ train/test ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏•‡∏∞ distribution")
    
    # 4. Temporal Leakage Check (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ date columns)
    date_cols = train_df.select_dtypes(include=['datetime64']).columns
    if len(date_cols) > 0:
        print(f"\nüìÖ Date columns found: {list(date_cols)}")
        print("‚ö†Ô∏è  Warning: ‡∏£‡∏∞‡∏ß‡∏±‡∏á temporal leakage!")
        print("üí° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ features ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏±‡∏á target ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô")
    
    print("\n" + "="*70)
    if suspicious_features:
        print(f"‚ùå ‡∏û‡∏ö {len(suspicious_features)} features ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢")
        print("üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ features ‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô model ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà")
    else:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏≠‡∏á data leakage")
    
    return suspicious_features

# ==================== MULTICOLLINEARITY DETECTION ====================

def check_multicollinearity(df, threshold=0.8):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Multicollinearity (features ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ô‡∏™‡∏π‡∏á)
    """
    print("="*70)
    print("üîç MULTICOLLINEARITY CHECK")
    print("="*70)
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) < 2:
        print("‚ö†Ô∏è  ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ numeric features ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 features")
        return []
    
    corr_matrix = df[numeric_cols].corr().abs()
    
    # ‡∏´‡∏≤ feature pairs ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if corr_matrix.iloc[i, j] > threshold:
                high_corr_pairs.append({
                    'feature_1': corr_matrix.columns[i],
                    'feature_2': corr_matrix.columns[j],
                    'correlation': corr_matrix.iloc[i, j]
                })
    
    if high_corr_pairs:
        print(f"\n‚ö†Ô∏è  ‡∏û‡∏ö {len(high_corr_pairs)} feature pairs ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏π‡∏á (>{threshold}):\n")
        pairs_df = pd.DataFrame(high_corr_pairs).sort_values('correlation', ascending=False)
        print(pairs_df.head(10))
        
        print(f"\nüí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print(f"   1. ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏•‡∏ö features ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô")
        print(f"   2. ‡πÉ‡∏ä‡πâ PCA ‡∏´‡∏£‡∏∑‡∏≠ feature selection")
        print(f"   3. ‡πÉ‡∏ä‡πâ regularization (Ridge/Lasso)")
        
        # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö
        feature_counts = {}
        for pair in high_corr_pairs:
            feature_counts[pair['feature_1']] = feature_counts.get(pair['feature_1'], 0) + 1
            feature_counts[pair['feature_2']] = feature_counts.get(pair['feature_2'], 0) + 1
        
        sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)
        print(f"\nüéØ Features ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö features ‡∏≠‡∏∑‡πà‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î:")
        for feat, count in sorted_features[:5]:
            print(f"   - {feat}: ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö {count} features")
    else:
        print("‚úÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤ multicollinearity")
    
    return high_corr_pairs

# ==================== MODEL RECOMMENDATION ====================

def suggest_models(train_df, target_col, task='auto'):
    """
    ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏°‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    print("="*70)
    print("ü§ñ MODEL RECOMMENDATION")
    print("="*70)
    
    n_samples = len(train_df)
    n_features = len(train_df.columns) - 1
    
    # Detect task type
    if task == 'auto':
        if train_df[target_col].dtype == 'object' or train_df[target_col].nunique() < 20:
            task = 'classification'
        else:
            task = 'regression'
    
    print(f"\nüìä Dataset Info:")
    print(f"   - Task: {task.upper()}")
    print(f"   - Samples: {n_samples:,}")
    print(f"   - Features: {n_features}")
    print(f"   - Sample/Feature Ratio: {n_samples/n_features:.1f}")
    
    recommendations = []
    
    # Size-based recommendations
    if n_samples < 1000:
        print(f"\nüìâ Dataset Size: SMALL (<1,000 samples)")
        recommendations.extend([
            "ü•á Ridge/Lasso Regression (simple, less overfitting)" if task == 'regression' else "ü•á Logistic Regression",
            "ü•à Random Forest (small n_estimators)",
            "ü•â Gradient Boosting (small n_estimators, high learning_rate)"
        ])
        print("‚ö†Ô∏è  Warning: ‡∏£‡∏∞‡∏ß‡∏±‡∏á overfitting! ‡πÉ‡∏ä‡πâ regularization ‡πÅ‡∏•‡∏∞ cross-validation")
        
    elif n_samples < 10000:
        print(f"\nüìä Dataset Size: MEDIUM (1K-10K samples)")
        recommendations.extend([
            "ü•á LightGBM / XGBoost",
            "ü•à Random Forest",
            "ü•â CatBoost (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ categorical features ‡πÄ‡∏¢‡∏≠‡∏∞)"
        ])
        
    else:
        print(f"\nüìà Dataset Size: LARGE (>10K samples)")
        recommendations.extend([
            "ü•á LightGBM (‡πÄ‡∏£‡πá‡∏ß, ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥)",
            "ü•à XGBoost",
            "ü•â Neural Networks (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ features ‡πÄ‡∏¢‡∏≠‡∏∞‡∏°‡∏≤‡∏Å)"
        ])
    
    # Feature-based recommendations
    cat_features = len(train_df.select_dtypes(include=['object']).columns)
    if cat_features > 5:
        print(f"\nüìù Categorical Features: {cat_features}")
        recommendations.append("üí° CatBoost ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏°‡∏≤‡∏Å (handle categorical ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)")
    
    # Ratio-based warnings
    if n_samples / n_features < 5:
        print(f"\n‚ö†Ô∏è  Warning: Feature ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ samples!")
        print("üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: Feature selection, PCA, ‡∏´‡∏£‡∏∑‡∏≠ regularization")
    
    print(f"\nüéØ Recommended Models:")
    for i, rec in enumerate(recommendations[:5], 1):
        print(f"   {i}. {rec}")
    
    return recommendations

# ==================== OVERFITTING DETECTION ====================

def detect_overfitting(model, X_train, y_train, X_val, y_val, task='regression'):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Overfitting ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö train vs validation score
    """
    print("="*70)
    print("üîç OVERFITTING DETECTION")
    print("="*70)
    
    # Train and predict
    model.fit(X_train, y_train)
    train_pred = model.predict(X_train)
    val_pred = model.predict(X_val)
    
    if task == 'regression':
        train_score = np.sqrt(mean_squared_error(y_train, train_pred))
        val_score = np.sqrt(mean_squared_error(y_val, val_pred))
        metric_name = "RMSE"
        # Lower is better for RMSE
        gap = val_score - train_score
        gap_pct = (gap / train_score) * 100
    else:
        if hasattr(model, 'predict_proba'):
            train_pred_proba = model.predict_proba(X_train)[:, 1]
            val_pred_proba = model.predict_proba(X_val)[:, 1]
            train_score = roc_auc_score(y_train, train_pred_proba)
            val_score = roc_auc_score(y_val, val_pred_proba)
        else:
            train_score = model.score(X_train, y_train)
            val_score = model.score(X_val, y_val)
        metric_name = "AUC" if hasattr(model, 'predict_proba') else "Accuracy"
        # Higher is better for AUC/Accuracy
        gap = train_score - val_score
        gap_pct = (gap / train_score) * 100
    
    print(f"\nüìä Performance Metrics:")
    print(f"   Train {metric_name}: {train_score:.4f}")
    print(f"   Val {metric_name}: {val_score:.4f}")
    print(f"   Gap: {gap:.4f} ({gap_pct:.1f}%)")
    
    # Diagnosis
    print(f"\nüîç Diagnosis:")
    if abs(gap_pct) < 5:
        print("   ‚úÖ Good fit! Train ‡πÅ‡∏•‡∏∞ validation scores ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô")
        status = "good_fit"
    elif gap_pct > 15:
        print("   ‚ùå OVERFITTING detected!")
        print("   üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print("      1. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training")
        print("      2. ‡πÉ‡∏ä‡πâ regularization (Ridge, Lasso, or L1/L2)")
        print("      3. ‡∏•‡∏î model complexity (max_depth, n_estimators)")
        print("      4. ‡πÄ‡∏û‡∏¥‡πà‡∏° dropout (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö neural networks)")
        print("      5. ‡πÉ‡∏ä‡πâ early stopping")
        print("      6. ‡∏ó‡∏≥ feature selection")
        status = "overfitting"
    elif gap_pct < -15:
        print("   ‚ö†Ô∏è  UNDERFITTING detected!")
        print("   üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print("      1. ‡πÄ‡∏û‡∏¥‡πà‡∏° model complexity")
        print("      2. ‡πÄ‡∏û‡∏¥‡πà‡∏° features")
        print("      3. ‡∏•‡∏î regularization")
        print("      4. Train ‡∏ô‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô (‡πÄ‡∏û‡∏¥‡πà‡∏° n_estimators)")
        status = "underfitting"
    else:
        print("   ‚ö†Ô∏è  Slight overfitting - ‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ")
        status = "slight_overfitting"
    
    return {
        'train_score': train_score,
        'val_score': val_score,
        'gap': gap,
        'gap_percentage': gap_pct,
        'status': status
    }

# ==================== LEARNING CURVE ANALYSIS ====================

def plot_learning_curve(model, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1):
    """
    Plot learning curve ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå overfitting/underfitting
    """
    print("üìà Generating learning curve...")
    
    train_sizes, train_scores, val_scores = learning_curve(
        model, X, y, cv=cv, scoring=scoring,
        n_jobs=n_jobs, train_sizes=np.linspace(0.1, 1.0, 10)
    )
    
    train_mean = -train_scores.mean(axis=1) if 'neg' in scoring else train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = -val_scores.mean(axis=1) if 'neg' in scoring else val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
    plt.plot(train_sizes, val_mean, label='Validation score', color='red', marker='o')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')
    
    plt.xlabel('Training Set Size')
    plt.ylabel('Score')
    plt.title('Learning Curve')
    plt.legend(loc='best')
    plt.grid(True, alpha=0.3)
    
    # Diagnosis
    final_gap = abs(val_mean[-1] - train_mean[-1])
    if final_gap < 0.05 * train_mean[-1]:
        diagnosis = "‚úÖ Good fit"
    elif val_mean[-1] < train_mean[-1]:
        diagnosis = "‚ùå Overfitting - validation score ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ train score"
    else:
        diagnosis = "‚ö†Ô∏è  Underfitting - ‡∏ó‡∏±‡πâ‡∏á train ‡πÅ‡∏•‡∏∞ val scores ‡∏ï‡πà‡∏≥"
    
    plt.text(0.02, 0.98, diagnosis, transform=plt.gca().transAxes,
             fontsize=12, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    plt.tight_layout()
    plt.show()
    
    print(f"\nüîç Analysis:")
    print(f"   Final Training Score: {train_mean[-1]:.4f}")
    print(f"   Final Validation Score: {val_mean[-1]:.4f}")
    print(f"   {diagnosis}")

# ==================== COMPREHENSIVE DIAGNOSIS ====================

def quick_diagnosis(train_df, target_col, test_df=None, model=None, X_val=None, y_val=None):
    """
    ‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏î‡πà‡∏ß‡∏ô - ‡∏£‡∏ß‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    """
    print("üè• QUICK DIAGNOSIS - Comprehensive Data & Model Check")
    print("="*70)
    
    # 1. Data Quality
    print("\n" + "üîπ"*35)
    quality_report = check_data_quality(train_df, target_col, show_details=False)
    
    # 2. Data Leakage
    print("\n" + "üîπ"*35)
    suspicious_features = detect_leakage(train_df, target_col, test_df)
    
    # 3. Multicollinearity
    print("\n" + "üîπ"*35)
    X = train_df.drop(columns=[target_col])
    multicollinearity = check_multicollinearity(X, threshold=0.8)
    
    # 4. Model Recommendation
    print("\n" + "üîπ"*35)
    model_recommendations = suggest_models(train_df, target_col)
    
    # 5. Overfitting Check (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ model)
    if model is not None and X_val is not None and y_val is not None:
        print("\n" + "üîπ"*35)
        X_train = train_df.drop(columns=[target_col])
        y_train = train_df[target_col]
        task = 'classification' if train_df[target_col].dtype == 'object' or train_df[target_col].nunique() < 20 else 'regression'
        overfitting_report = detect_overfitting(model, X_train, y_train, X_val, y_val, task)
    
    # 6. Summary Report
    print("\n" + "="*70)
    print("üìã FINAL REPORT")
    print("="*70)
    
    total_issues = len(quality_report['issues']) + len(quality_report['warnings']) + len(suspicious_features)
    
    if total_issues == 0:
        print("\n‚úÖ‚úÖ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ! ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
    else:
        print(f"\n‚ö†Ô∏è  ‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_issues}")
        
        print(f"\nüî¥ Priority Issues:")
        priority_actions = []
        
        if quality_report['constant_features']:
            priority_actions.append("1. ‡∏•‡∏ö constant features")
        if suspicious_features:
            priority_actions.append("2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data leakage features")
        if len(multicollinearity) > 10:
            priority_actions.append("3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ multicollinearity")
        if quality_report['high_missing_features']:
            priority_actions.append("4. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values")
        
        for action in priority_actions:
            print(f"   {action}")
    
    print(f"\nüéØ Recommended Next Steps:")
    print(f"   1. {model_recommendations[0] if model_recommendations else 'Run quick_model_comparison()'}")
    print(f"   2. ‡πÉ‡∏ä‡πâ cross-validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    print(f"   3. Plot learning curves ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö overfitting")
    print(f"   4. ‡∏ó‡∏≥ feature engineering ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
    
    return {
        'quality_report': quality_report,
        'suspicious_features': suspicious_features,
        'multicollinearity_count': len(multicollinearity),
        'model_recommendations': model_recommendations
    }

# ==================== FEATURE IMPORTANCE ANALYSIS ====================

def analyze_feature_importance_detailed(model, X, y, feature_names, top_n=20):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á features ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    """
    print("="*70)
    print("üéØ DETAILED FEATURE IMPORTANCE ANALYSIS")
    print("="*70)
    
    from sklearn.inspection import permutation_importance
    
    # 1. Built-in importance (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if hasattr(model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nüìä Built-in Feature Importance (Top 20):")
        print(importance_df.head(top_n))
        
        # Plot
        plt.figure(figsize=(10, 8))
        top_features = importance_df.head(top_n)
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('Importance')
        plt.title('Feature Importance')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()
    
    # 2. Permutation Importance
    print("\nüîÑ Computing Permutation Importance...")
    perm_importance = permutation_importance(model, X, y, n_repeats=10, random_state=42, n_jobs=-1)
    
    perm_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance_mean': perm_importance.importances_mean,
        'importance_std': perm_importance.importances_std
    }).sort_values('importance_mean', ascending=False)
    
    print("\nüìä Permutation Importance (Top 20):")
    print(perm_importance_df.head(top_n))
    
    # 3. Features ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏•‡∏ö
    low_importance = importance_df[importance_df['importance'] < 0.001] if hasattr(model, 'feature_importances_') else perm_importance_df[perm_importance_df['importance_mean'] < 0.001]
    
    if len(low_importance) > 0:
        print(f"\nüí° ‡∏û‡∏ö {len(low_importance)} features ‡∏ó‡∏µ‡πà‡∏°‡∏µ importance ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (<0.001):")
        print(f"   ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏•‡∏ö features: {list(low_importance['feature'].head(10))}")
    
    return importance_df if hasattr(model, 'feature_importances_') else perm_importance_df

print("‚úÖ Diagnostics module loaded successfully!")